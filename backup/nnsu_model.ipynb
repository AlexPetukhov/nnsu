{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Untitled15.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "authorship_tag": "ABX9TyOM+3KxwG70gLFfWg0nh7FK"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "D-e5kdMhLq42"
   },
   "source": [
    "# from google.colab import drive\n",
    "import keras\n",
    "from keras.models import load_model\n",
    "import keras.layers as L\n",
    "import numpy as np"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "hoN8X-6IEahY"
   },
   "source": [
    "filter_means = np.array([32, 32, 256, 256, 256, 512, 512, 512, 512])\n",
    "filter_means_2 = filter_means"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "dLcaYVYmXYzf"
   },
   "source": [
    "def get_conv_model(filter_means, input_layer):\n",
    "  for i in range(len(filter_means)):\n",
    "    if i == 0:\n",
    "      conv = L.Conv1D(filters=filter_means[i], kernel_size=9, padding='same', strides=5, activation='relu')(input_layer)\n",
    "    else:\n",
    "      conv = L.Conv1D(filters=filter_means[i], kernel_size=9, padding='same', strides=5, activation='relu')(relu)\n",
    "    drop = L.Dropout(0.25)(conv)\n",
    "    conv = L.Conv1D(filters=filter_means[i], kernel_size=9, padding='same', strides=5)(drop)\n",
    "    batch = L.BatchNormalization()(conv)\n",
    "    #pool = L.MaxPool1D(2)(batch)\n",
    "    relu = L.ReLU()(batch)\n",
    "    drop = L.Dropout(0.25)(relu)\n",
    "  #return L.Lambda(lambda x: L.K.batch_flatten(x))(relu)\n",
    "  return L.Flatten()(drop)"
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "jQ5sEFeNJWq5"
   },
   "source": [
    "def model_many_diseases2():\n",
    "  input_layer = L.Input(shape=(4500, 12))\n",
    "  input_layer2 = L.Input(shape=(4500, 4))\n",
    "  input_layer3 = L.Input(shape=(60,))\n",
    "  # inp\n",
    "  model_12 = get_conv_model(filter_means[:2], input_layer)\n",
    "  model_4 = get_conv_model(filter_means_2[:2], input_layer2)\n",
    "  \n",
    "  merged = L.Concatenate(axis=1)([model_12, model_4])\n",
    "  merged2 = L.Concatenate(axis=1)([model_12, model_4, input_layer3])\n",
    "\n",
    "  #dense_1_1 = L.Dense(1024, activation='relu')(merged)\n",
    "  dense_1_2 = L.Dense(512, activation='relu')(merged)\n",
    "  dense_2_2 = L.Dense(512, activation='relu')(merged)\n",
    "  dense_3_2 = L.Dense(512, activation='relu')(merged)\n",
    "  dense_4_2 = L.Dense(512, activation='relu')(merged)\n",
    "  dense_5_2 = L.Dense(512, activation='relu')(merged)\n",
    "  #dense_6_2 = L.Dense(512, activation='relu')(merged)\n",
    "  dense_7_2 = L.Dense(572, activation='relu')(merged2)\n",
    "  \n",
    "  #dense_rhythm = L.Dense(4, activation='softmax')(dense_1_2)\n",
    "  #dense_hyper = L.Dense(1, activation='sigmoid')(dense_2_2)\n",
    "  \n",
    "  dense_rhythm = L.Dense(4, activation='softmax')(dense_1_2)\n",
    "  dense_hyper = L.Dense(1, activation='sigmoid')(dense_2_2)\n",
    "  dense_extr = L.Dense(1, activation='sigmoid')(dense_3_2)\n",
    "  dense_av = L.Dense(1, activation='sigmoid')(dense_4_2)\n",
    "  dense_gis1 = L.Dense(1, activation='sigmoid')(dense_5_2)\n",
    "  dense_gis2 = L.Dense(1, activation='sigmoid')(dense_5_2)\n",
    "  dense_gis3 = L.Dense(1, activation='sigmoid')(dense_5_2)\n",
    "  dense_gis4 = L.Dense(1, activation='sigmoid')(dense_5_2)\n",
    "  dense_gis5 = L.Dense(1, activation='sigmoid')(dense_5_2)\n",
    "  dense_gis6 = L.Dense(1, activation='sigmoid')(dense_5_2)\n",
    "  #dense_isc = L.Dense(1, activation='sigmoid')(dense_6_2)\n",
    "  dense_axis = L.Dense(9, activation='softmax')(dense_7_2)\n",
    "  \n",
    "  model = keras.Model([input_layer,input_layer2,input_layer3], [dense_rhythm,dense_hyper,dense_extr,dense_av,dense_gis1,dense_gis2,dense_gis3,\n",
    "                                                      dense_gis4,dense_gis5,dense_gis6,dense_axis])\n",
    "  return model"
   ],
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "C-e8xzcXMF8Q"
   },
   "source": [
    "model = model_many_diseases2()"
   ],
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "m4XhKgk9MDjW"
   },
   "source": [
    "model.compile(loss=[\"sparse_categorical_crossentropy\",\"binary_crossentropy\",\"binary_crossentropy\",\n",
    "                            \"binary_crossentropy\",\"binary_crossentropy\",\"binary_crossentropy\",\n",
    "                           \"binary_crossentropy\",\"binary_crossentropy\",\"binary_crossentropy\",\"binary_crossentropy\",\n",
    "                           \"sparse_categorical_crossentropy\"], optimizer=keras.optimizers.Adam(), metrics=['accuracy'])"
   ],
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9kJUIHPGL-l9"
   },
   "source": [
    "def generator_st(x_train, y_train, batch_size, num_leads, out_neurons):\n",
    "  # Create empty arrays to contain batch of features and labels#\n",
    "  if (num_leads == 12):\n",
    "    FLAG = 0\n",
    "    batch_features = np.zeros((batch_size, 4500, 12))\n",
    "  else:\n",
    "    FLAG = 1\n",
    "    batch_features_1 = np.zeros((batch_size, 4500, 12))\n",
    "    batch_features_2 = np.zeros((batch_size, 4500, 4))\n",
    "    batch_features_3 = np.zeros((batch_size, 60))\n",
    "    \n",
    "  if len(out_neurons) == 1:\n",
    "    batch_labels = np.zeros((batch_size, out_neurons[0]))\n",
    "  else:\n",
    "    batch_labels = []\n",
    "    for i in range(len(out_neurons)):\n",
    "      batch_lab = np.zeros((batch_size, out_neurons[i]))\n",
    "      batch_labels.append(batch_lab)\n",
    "  \n",
    "  if (FLAG == 0):\n",
    "    while True:\n",
    "      for i in range(batch_size):\n",
    "          # choose random index in features\n",
    "          index = np.random.choice(len(x_train), 1)[0]\n",
    "          mu, sigma = 0, 0.5 \n",
    "          noise = np.random.normal(mu, sigma, [3000,12])\n",
    "          shift = np.random.randint(0, 501, 1)[0]\n",
    "          batch_features[i] = x_train[index, shift:shift+3000, :] + noise \n",
    "          if len(out_neurons) == 1:\n",
    "            batch_labels[i] = y_train[index]\n",
    "          else:\n",
    "            for j in range(len(out_neurons)):\n",
    "              batch_labels[j][i] = y_train[j][index]\n",
    "          \n",
    "      yield batch_features, batch_labels\n",
    "      \n",
    "  elif (FLAG == 1):\n",
    "    while True:\n",
    "      for i in range(batch_size):\n",
    "          # choose random index in features\n",
    "          index = np.random.choice(len(x_train[0]), 1)[0]\n",
    "          shift = np.random.randint(0, 501, 1)[0]\n",
    "          mu, sigma = 0, 0.3\n",
    "          noise = np.random.normal(mu, sigma, [4500,12])\n",
    "          noise2 = np.random.normal(mu, sigma, [4500,4])\n",
    "\n",
    "          batch_features_1[i] = x_train[0][index, shift:shift+4500]# + np.sin(noise)\n",
    "          batch_features_2[i] = x_train[1][index, shift:shift+4500] \n",
    "          batch_features_3[i, :12] = batch_features_1[i].max(axis=0)\n",
    "          batch_features_3[i, 12:24] = batch_features_1[i].min(axis=0)\n",
    "          batch_features_3[i, 24:36] = batch_features_1[i].mean(axis=0)\n",
    "          batch_features_3[i, 36:48] = batch_features_1[i].std(axis=0)\n",
    "          batch_features_3[i, 48:] = batch_features_1[i].max(axis=0) + batch_features_1[i].min(axis=0)\n",
    "          #batch_features_3[i] = x_train[2][index, :]\n",
    "          if len(out_neurons) == 1:\n",
    "            batch_labels[i] = y_train[index]\n",
    "          else:\n",
    "            for j in range(len(out_neurons)):\n",
    "              batch_labels[j][i] = y_train[j][index]\n",
    "            \n",
    "      yield [batch_features_1, batch_features_2,batch_features_3], batch_labels"
   ],
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_pmhYl5XL-ok"
   },
   "source": [
    "history = model.fit_generator(generator_st([x_train[:,:,:12],x_train[:,:,12:]], [y_train, y_train_hyper, y_train_extr, y_train_av, y_train_gis[:,0],\n",
    "                                                                                y_train_gis[:,1] ,y_train_gis[:,2] ,y_train_gis[:,3], y_train_gis[:,4],\n",
    "                                                                                y_train_gis[:,5] , y_train_axis], 128, 16, [1,1,1,1,1,1,1,1,1,1,1]), epochs=1, steps_per_epoch=8,\n",
    "                                     validation_data=([x_test[:,0:4500,:12],x_test[:,0:4500,12:],x_test1], [y_test, y_test_hyper, y_test_extr, y_test_av, y_test_gis[:,0],\n",
    "                                                                                y_test_gis[:,1] ,y_test_gis[:,2] ,y_test_gis[:,3], y_test_gis[:,4],\n",
    "                                                                                y_test_gis[:,5] , y_test_axis]), class_weight = [{0:0.35010338, 1:1.66013072, 2:11.04347826, 3:2.21834061},\n",
    "                                                                                                                                 {0:1.25925926, 1:0.82926829},\n",
    "                                                                                                                                 {0:0.52211302, 1:11.80555556},\n",
    "                                                                                                                                 {0:0.52696838, 1:9.77011494},\n",
    "                                                                                                                                 {0:0.57744565, 1:3.72807018}, {0:0.50535077 ,1:47.22222222}, {0:5.00294291e-01 ,1:8.50000000e+02},\n",
    "                                                                                                                                 {0:0.55230669 ,1:5.27950311}, {0:0.51924252 ,1:13.49206349}, {0:0.51515152 ,1:17},\n",
    "                                                                                                                                 {0:1, 1:13.28125   ,  2:1.40728477,  3:0.37677305,  4:1.02163462,  5:0.4009434 , 6:3.86363636, 7:35.41666667,  8:1.25      }])"
   ],
   "execution_count": 10,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-10-cde1add02a86>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m history = model.fit_generator(generator_st([x_train[:,:,:12],x_train[:,:,12:]], [y_train, y_train_hyper, y_train_extr, y_train_av, y_train_gis[:,0],\n\u001B[0m\u001B[1;32m      2\u001B[0m                                                                                 \u001B[0my_train_gis\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m,\u001B[0m\u001B[0my_train_gis\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m,\u001B[0m\u001B[0my_train_gis\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m3\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_train_gis\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m4\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m                                                                                 y_train_gis[:,5] , y_train_axis], 128, 16, [1,1,1,1,1,1,1,1,1,1,1]), epochs=1, steps_per_epoch=8,\n\u001B[1;32m      4\u001B[0m                                      validation_data=([x_test[:,0:4500,:12],x_test[:,0:4500,12:],x_test1], [y_test, y_test_hyper, y_test_extr, y_test_av, y_test_gis[:,0],\n\u001B[1;32m      5\u001B[0m                                                                                 \u001B[0my_test_gis\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m,\u001B[0m\u001B[0my_test_gis\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m,\u001B[0m\u001B[0my_test_gis\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m3\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_test_gis\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m4\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'x_train' is not defined"
     ]
    }
   ]
  }
 ]
}